---
layout: post
title: Understanding reservoir sampling
image: /public/images/reservoir_sampling.jpg
summary: >
    Reservoir sampling is a technique that allows you to pull a random sample of a series that's too large to fit into memory, or forever whatever other reason (maybe it's coming across an intermittent network connection) you can't access all at once.
---

Taking a random sample of a series is a pretty fundamental operation in many contexts. However, the naive approach -- taking `k` items from a list as chosen by a random function -- doesn't work when you don't know how many items are in the series, either because you don't have them all yet (maybe they're streaming across the network) or because they're too big to fit into memory all at once (sample all of the events generated by your wildly popular web app over the last 24 hours). What is a software engineer to do?

Reservoir sampling is an approach that solves this very problem.

### The algorithm

Take the first `k` elements of `source`, your massive list of objects (we'll call it `source`), and put them in the sample set (we'll call it `sample`). Starting with the next element (`source[k]`), iterate through `source` and on each element randomly choose an element in `sample` and replace with the current object in `source`, maybe.

The "maybe" is the important part. At each iteration the odds of replacing a value should decrease proportional to the number of iterations already made. This ensures that the odds of any given element being included in `sample` are the same -- as the number of iterations increases, the *opportunities* for being replace increase, but the *probability* of being replaced each time decreases. Because they change proportionally, the odds always remain the same.

### The code

{% highlight python %}
from random import randint

def reservoir_sample(source, k):
    if len(source) <= k:
        return source[::]  # just copy source
    
    sample = source[:k]
    for idx, n in enumerate(source[k:], start=k):
        ridx = randint(0, i)
        if ridx < k:
            sample[ridx] = source[idx]
    return sample

# Visually verify that the sampling looks legit
from collections import Counter

for _ in range(100000):
    x = sample([1, 2, 3, 4], 1)
    key = x[0]
    c[key] += 1

print(c)
# Counter({3: 25155, 2: 25026, 4: 24916, 1: 24903})
{% endhighlight %}

Of course this is a trivial example -- the total population is clearly within our computer's ability to load into memory -- and in real life you'd probably wrap this in an object that would take new values and return the current sample whenever asked. The mechanics for it are the same, though.
